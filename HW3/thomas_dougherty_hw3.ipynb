{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Homework 3\n",
    "<p> Thomas Dougherty <br>\n",
    "9/28/2023 <br>\n",
    "Deep Learning</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "\n",
    "# download training data\n",
    "train_data = CIFAR10(root=\"./train/\",\n",
    "                     train=True,\n",
    "                     download=True,\n",
    "                     transform=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`How do you access the label?` <br>\n",
    "<p> The label can be accessed with with direct indexing of the [1] index of a train_data[i] tuple </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Label: 9\n",
      "Class: truck\n"
     ]
    }
   ],
   "source": [
    "label = train_data[16][1]\n",
    "data_class = train_data.classes[train_data[16][1]]\n",
    "print(f'Data Label: {label}')                       # print the label of the tuple\n",
    "print(f'Class: {data_class}')    # print the class of the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`What method is called when you index into a Dataset?`\n",
    "\n",
    "The Dataset function __getitem__(self, index: int) is called. It takes a self-reference and integer as arguments to return a tuple containing the image and target class.\n",
    "\n",
    "`Is CIFAR10 a class that is derived from the Dataset class?`\n",
    "\n",
    "Yes, CIFAR10 is a subclass of Dataset that inherits the __getitem__ and __len__ methods from Dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Inheritance Tree` <br>\n",
    "![Alt text](dataset-inherit.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-process the data before running through a neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data without transforms: <PIL.Image.Image image mode=RGB size=32x32 at 0x7F6741977A30>\n",
      "Data Label: 9\n",
      "Training data with transforms: tensor([[[ 2.1652,  2.1652,  2.1652,  ..., -2.4291, -2.4291, -2.4291],\n",
      "         [ 2.1652,  2.1652,  2.1845,  ..., -2.4291, -2.4291, -2.4291],\n",
      "         [ 2.1458,  2.1652,  2.2233,  ..., -2.4291, -2.4291, -2.4291],\n",
      "         ...,\n",
      "         [-2.4291, -2.4291, -2.4291,  ..., -2.4291, -2.4291, -2.4291],\n",
      "         [-2.4291, -2.4291, -2.4291,  ..., -2.4291, -2.4291, -2.4291],\n",
      "         [-2.4291, -2.4291, -2.4291,  ..., -2.4291, -2.4291, -2.4291]],\n",
      "\n",
      "        [[ 2.2625,  2.2625,  2.2625,  ..., -2.4183, -2.4183, -2.4183],\n",
      "         [ 2.2625,  2.2625,  2.2821,  ..., -2.4183, -2.4183, -2.4183],\n",
      "         [ 2.2428,  2.2625,  2.3215,  ..., -2.4183, -2.4183, -2.4183],\n",
      "         ...,\n",
      "         [-2.4183, -2.4183, -2.4183,  ..., -2.4183, -2.4183, -2.4183],\n",
      "         [-2.4183, -2.4183, -2.4183,  ..., -2.4183, -2.4183, -2.4183],\n",
      "         [-2.4183, -2.4183, -2.4183,  ..., -2.4183, -2.4183, -2.4183]],\n",
      "\n",
      "        [[ 2.4611,  2.4611,  2.4611,  ..., -2.2214, -2.2214, -2.2214],\n",
      "         [ 2.4611,  2.4611,  2.4806,  ..., -2.2214, -2.2214, -2.2214],\n",
      "         [ 2.4416,  2.4611,  2.5196,  ..., -2.2214, -2.2214, -2.2214],\n",
      "         ...,\n",
      "         [-2.2214, -2.2214, -2.2214,  ..., -2.2214, -2.2214, -2.2214],\n",
      "         [-2.2214, -2.2214, -2.2214,  ..., -2.2214, -2.2214, -2.2214],\n",
      "         [-2.2214, -2.2214, -2.2214,  ..., -2.2214, -2.2214, -2.2214]]])\n",
      "Data Label: 9\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# TRAINING DATA\n",
    "\n",
    "# taking mean and std values from the book\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.Normalize(mean=(0.4914, 0.4822, 0.4465),\n",
    "                        std=(0.2023, 0.1994, 0.201)),\n",
    "])\n",
    "\n",
    "train_data_xform = CIFAR10(root=\"./train/\",\n",
    "                     train=True,\n",
    "                     transform=train_transform)\n",
    "\n",
    "data, label = train_data[16]\n",
    "print(f'Training data without transforms: {data}')\n",
    "print(f'Data Label: {label}')\n",
    "\n",
    "data, label = train_data_xform[16]\n",
    "print(f'Training data with transforms: {data}')\n",
    "print(f'Data Label: {label}')\n",
    "\n",
    "\n",
    "# TESTING DATA\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        (0.4914, 0.4822, 0.4465),\n",
    "        (0.2023, 0.1994, 0.2010))\n",
    "    ])\n",
    "\n",
    "test_data = CIFAR10(root=\"./test/\",\n",
    "                     train=False,\n",
    "                     transform=test_transform,\n",
    "                     download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`When you instantiate train_data the second time, with the transform, try without download=True. Look at the API. What does it say?`\n",
    "<p>If download is set to 'True', the data is downloaded to the root directory, otherwise it will verify the data has been downloaded. If the 'download' option is not included and the Dataset is not found, it will cause a runtime error.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`What is the difference between training and testing transforms? Training is supposed to ”see” more data variability and that is why we provide augmentations of the original data through transforms. Why do you think the test dataset has a different transform?`\n",
    "\n",
    "The training transform has augmentations such as horizontal flips and random crops whereas the testing data is unaltered aside from normalization. Keeping the two sets seperated like this helps simulate real-world variabiltiy and the model will make generalizations about unseen data. Augmenting the testing data the same way as the training data may lead to overly-optimistic results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Please do` <br>\n",
    "`data, label = train_data[index] in both cases (with and without transforms).`<br>\n",
    "`Why is your result different when you apply transforms?`\n",
    "\n",
    "Before transforms are applied, the data is raw. When accessing train_data[index], metadata is returned such as the color mode, size, and address in memory. When the data is processed with a transform, it's changed into a tensor so that it is readable by a machine learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Batching\n",
    "<p> I've noticed that bigger batch size results in faster training times, likely because it takes better advtange of GPU parallelism. However, it also leads to higher loss value. The larger batch size causes a smoother average since extreme or outlying datapoints have less influence over the loss value. The learning rate and the number of epochs has to be adjusted in order to get accurate results. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 3, 32, 32])\n",
      "torch.Size([512])\n"
     ]
    }
   ],
   "source": [
    "train_set, val_set = random_split(\n",
    "                      train_data_xform, \n",
    "                      [40000, 10000])\n",
    "\n",
    "batch_size = 512\n",
    "\n",
    "# Dataloader does all the work of shuffling data between batches and training cycles (epochs)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set,\n",
    "    batch_size,           # Bigger batch size results in faster training times, and higher memory usage\n",
    "    shuffle = True)\n",
    "\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_set,\n",
    "    batch_size,\n",
    "    shuffle = True)\n",
    "\n",
    "# create data batches\n",
    "data_batch, labels_batch = next(iter(train_loader))\n",
    "\n",
    "print(data_batch.size())\n",
    "print(labels_batch.size())\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data,\n",
    "    batch_size,\n",
    "    shuffle = False) # set shuffle to false for the testing data for repeatable results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thomas/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/thomas/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Layers: \n",
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "vgg16 = models.vgg16(pretrained=True)     # faster convergence on pre-trained models\n",
    "\n",
    "# Print layers of the neural network\n",
    "print(\"Neural Network Layers: \")\n",
    "print(vgg16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the Linear transformation layer with a new definition\n",
    "\"\"\"There are 10 classes in the CIFAR10 dataset, so 10 possible output features\"\"\"\n",
    "vgg16.classifier[-1] = nn.Linear(4096, 10)\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "model_vgg = vgg16.to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training\n",
    "\n",
    "<p> I spent too much time trying to debug the training loop when it kept crashing my laptop. Tried again on my desktop and it turned out my laptop just couldn't handle it The training loop took around 20-25 minutes to complete with the original parameters but I managed to get it down to around 6 minutes. It was fun playing around with this to get the loop to run in a more efficient way while trying to maintain around 80% accuracy </p> \n",
    "<br>\n",
    "Training: Find patters of a given data set <br>\n",
    "Validation: Tune hyperparameters and evaulate the model on a separate portion of the data set <br>\n",
    "Testing: Assess performance of the model with unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Epoch: 0 Training Loss: 1.0472834789300267\n",
      "VALIDATION\n",
      "Epoch: 0 Train Loss: 1.0472834789300267 Val Loss: 0.7708707064390182\n",
      "TRAINING\n",
      "Epoch: 1 Training Loss: 0.6240437034564682\n",
      "VALIDATION\n",
      "Epoch: 1 Train Loss: 0.6240437034564682 Val Loss: 0.5693194717168808\n",
      "TRAINING\n",
      "Epoch: 2 Training Loss: 0.4981967591786686\n",
      "VALIDATION\n",
      "Epoch: 2 Train Loss: 0.4981967591786686 Val Loss: 0.5287001490592956\n",
      "TRAINING\n",
      "Epoch: 3 Training Loss: 0.4372568458695955\n",
      "VALIDATION\n",
      "Epoch: 3 Train Loss: 0.4372568458695955 Val Loss: 0.45301304906606676\n",
      "TRAINING\n",
      "Epoch: 4 Training Loss: 0.38682634241973296\n",
      "VALIDATION\n",
      "Epoch: 4 Train Loss: 0.38682634241973296 Val Loss: 0.4452690929174423\n",
      "TRAINING\n",
      "Epoch: 5 Training Loss: 0.350644817835168\n",
      "VALIDATION\n",
      "Epoch: 5 Train Loss: 0.350644817835168 Val Loss: 0.42349734008312223\n",
      "TRAINING\n",
      "Epoch: 6 Training Loss: 0.3198577593776244\n",
      "VALIDATION\n",
      "Epoch: 6 Train Loss: 0.3198577593776244 Val Loss: 0.40564699172973634\n",
      "TRAINING\n",
      "Epoch: 7 Training Loss: 0.2948030256017854\n",
      "VALIDATION\n",
      "Epoch: 7 Train Loss: 0.2948030256017854 Val Loss: 0.3933153301477432\n",
      "TRAINING\n",
      "Epoch: 8 Training Loss: 0.27144272191615043\n",
      "VALIDATION\n",
      "Epoch: 8 Train Loss: 0.27144272191615043 Val Loss: 0.3913523733615875\n",
      "TRAINING\n",
      "Epoch: 9 Training Loss: 0.2520571677367898\n",
      "VALIDATION\n",
      "Epoch: 9 Train Loss: 0.2520571677367898 Val Loss: 0.37782281190156936\n",
      "TRAINING\n",
      "Epoch: 10 Training Loss: 0.22811409246317949\n",
      "VALIDATION\n",
      "Epoch: 10 Train Loss: 0.22811409246317949 Val Loss: 0.3791759580373764\n",
      "TRAINING\n",
      "Epoch: 11 Training Loss: 0.20974342298658588\n",
      "VALIDATION\n",
      "Epoch: 11 Train Loss: 0.20974342298658588 Val Loss: 0.46779278516769407\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 12\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model_vgg.parameters(),\n",
    "                      lr=0.010, \n",
    "                      momentum=0.9)\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    # TRAINING\n",
    "    train_loss = 0.0\n",
    "    model_vgg.train()\n",
    "    print(\"TRAINING\") \n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(device) \n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()   # forget errors of previous pass, let's start fresh\n",
    "\n",
    "        outputs = model_vgg(inputs)\n",
    "        loss = criterion(outputs, labels)   # compute loss\n",
    "        \n",
    "        loss.backward()         # backpropegation; compute gradient\n",
    "        \n",
    "        optimizer.step()        # adjust parameters based on gradient \n",
    "\n",
    "        train_loss += loss.item()\n",
    "    print(\"Epoch: {} Training Loss: {}\".format(epoch, \n",
    "                  train_loss/len(train_loader)))\n",
    "    \n",
    "    # VALIDATION\n",
    "    val_loss = 0.0\n",
    "    model_vgg.eval()\n",
    "    print(\"VALIDATION\")\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model_vgg(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        val_loss += loss.item()\n",
    "    print(\"Epoch: {} Train Loss: {} Val Loss: {}\".format(\n",
    "                  epoch, \n",
    "                  train_loss/len(train_loader), \n",
    "                  val_loss/len(val_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 512\n",
      "Test Accuracy: 0.83935546875\n"
     ]
    }
   ],
   "source": [
    "num_correct = 0.0\n",
    "\n",
    "for x_test_batch, y_test_batch in test_loader:\n",
    "\n",
    "    model_vgg.eval()\n",
    "    y_test_batch = y_test_batch.to(device)\n",
    "    x_test_batch = x_test_batch.to(device)\n",
    "\n",
    "    y_pred_batch = model_vgg(x_test_batch)\n",
    "    _, predicted = torch.max(y_pred_batch, 1)\n",
    "    num_correct += (predicted == y_test_batch).float().sum()\n",
    "\n",
    "vgg_accuracy = num_correct/(len(test_loader)*test_loader.batch_size)\n",
    "\n",
    "print(len(test_loader), test_loader.batch_size)\n",
    "print(\"Test Accuracy: {}\".format(vgg_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG16 vs LeNet5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LeNet class definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5) # <1>\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, int(x.nelement() / x.shape[0]))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "device = \"cuda\"\n",
    "model_lenet = LeNet5().to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LeNet training loop \n",
    "<p> Noticed that an excessively high learning rate tends to lead to poor performance. Probably from larger adjustments to model parameters and overshooting the optimal solution.</p>\n",
    "<p> It also tends to lead to a loss plateau. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Loss: 2.2516923886311204 Val Loss: 2.0793440103530885\n",
      "Epoch: 1 Train Loss: 1.9201205199277853 Val Loss: 1.7683249354362487\n",
      "Epoch: 2 Train Loss: 1.7125612814215165 Val Loss: 1.7482620179653168\n",
      "Epoch: 3 Train Loss: 1.6314312310158452 Val Loss: 1.5617895245552063\n",
      "Epoch: 4 Train Loss: 1.540311656420744 Val Loss: 1.501370108127594\n",
      "Epoch: 5 Train Loss: 1.49169121361986 Val Loss: 1.5180115044116973\n",
      "Epoch: 6 Train Loss: 1.4591672646848461 Val Loss: 1.4335203528404237\n",
      "Epoch: 7 Train Loss: 1.4107440906234934 Val Loss: 1.4246290266513824\n",
      "Epoch: 8 Train Loss: 1.3928079891808425 Val Loss: 1.3620448529720306\n",
      "Epoch: 9 Train Loss: 1.3453128051154222 Val Loss: 1.328314608335495\n",
      "Epoch: 10 Train Loss: 1.308727303637734 Val Loss: 1.4007271468639373\n",
      "Epoch: 11 Train Loss: 1.2928386715394031 Val Loss: 1.267656636238098\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(model_lenet.parameters(),\n",
    "                      lr=0.015,  \n",
    "                      momentum=0.9)\n",
    "\n",
    "# TRAINING\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    # Training \n",
    "    train_loss = 0.0\n",
    "    model_lenet.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model_lenet(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # Validation\n",
    "    val_loss = 0.0\n",
    "    model_lenet.eval()\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model_lenet(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        val_loss += loss.item()\n",
    "\n",
    "    print(\"Epoch: {} Train Loss: {} Val Loss: {}\".format(\n",
    "                  epoch, \n",
    "                  train_loss/len(train_loader), \n",
    "                  val_loss/len(val_loader)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 512\n",
      "LeNet5 Test Accuracy: 0.5594726800918579\n",
      "VGG16 Test Accuracy: 0.83935546875\n"
     ]
    }
   ],
   "source": [
    "num_correct = 0.0\n",
    "\n",
    "for x_test_batch, y_test_batch in test_loader:\n",
    "\n",
    "    model_lenet.eval()\n",
    "    y_test_batch = y_test_batch.to(device)\n",
    "    x_test_batch = x_test_batch.to(device)\n",
    "\n",
    "    y_pred_batch = model_lenet(x_test_batch)\n",
    "    _, predicted = torch.max(y_pred_batch, 1)\n",
    "    num_correct += (predicted == y_test_batch).float().sum()\n",
    "\n",
    "lenet_accuracy = num_correct/(len(test_loader)*test_loader.batch_size)\n",
    "\n",
    "print(len(test_loader), test_loader.batch_size)\n",
    "print(\"LeNet5 Test Accuracy: {}\".format(lenet_accuracy))\n",
    "print(\"VGG16 Test Accuracy: {}\".format(vgg_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Please compare these two performances on CIFAR10. Why is one better than another?`\n",
    "<p> VGG16 took longer but was much more accurate. LeNet5 had faster iterations but requires more epochs to achieve the same level of accuracy as VGG16. This is because VGG16 is a deeper neural network with 16 weight layers, 13 convolution layers, 5 max pooling layers, and 3 dense layers. This allows VGG16 to find more complex patterns compared to LeNet5's 2 convolution layers and 3 linear layers. </p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
