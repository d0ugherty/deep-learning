{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Homework 3\n",
    "<p> Thomas Dougherty <br>\n",
    "9/28/2023 <br>\n",
    "Deep Learning</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "\n",
    "# download training data\n",
    "train_data = CIFAR10(root=\"./train/\",\n",
    "                     train=True,\n",
    "                     download=True,\n",
    "                     transform=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`How do you access the label?` <br>\n",
    "<p> The label can be accessed with with direct indexing of the [1] index of a train_data[i] tuple </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Label: 9\n",
      "Class: truck\n"
     ]
    }
   ],
   "source": [
    "label = train_data[16][1]\n",
    "data_class = train_data.classes[train_data[16][1]]\n",
    "print(f'Data Label: {label}')                       # print the label of the tuple\n",
    "print(f'Class: {data_class}')    # print the class of the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`What method is called when you index into a Dataset?`\n",
    "\n",
    "The Dataset function __getitem__(self, index: int) is called. It takes a self-reference and integer as arguments to return a tuple containing the image and target class.\n",
    "\n",
    "`Is CIFAR10 a class that is derived from the Dataset class?`\n",
    "\n",
    "Yes, CIFAR10 is a subclass of Dataset that inherits the __getitem__ and __len__ methods from Dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Inheritance Tree` <br>\n",
    "![Alt text](dataset-inherit.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-process the data before running through a neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data without transforms: <PIL.Image.Image image mode=RGB size=32x32 at 0x7FF6A4D6A080>\n",
      "Data Label: 9\n",
      "Training data with transforms: tensor([[[ 2.1264,  2.1652,  2.2039,  ...,  1.9713,  1.8938, -2.4291],\n",
      "         [ 2.0682,  2.1070,  2.1458,  ...,  1.9325,  1.8550, -2.4291],\n",
      "         [ 2.0876,  2.1652,  2.1652,  ...,  1.9325,  1.8550, -2.4291],\n",
      "         ...,\n",
      "         [ 0.0134,  0.3430,  0.4787,  ..., -1.1690, -1.1109, -2.4291],\n",
      "         [ 0.3042,  0.4593,  0.3817,  ..., -1.1303, -1.2272, -2.4291],\n",
      "         [ 0.3236,  0.4593,  0.3817,  ..., -1.2466, -1.4404, -2.4291]],\n",
      "\n",
      "        [[ 2.2231,  2.2625,  2.3018,  ...,  2.1051,  2.0658, -2.4183],\n",
      "         [ 2.1641,  2.2035,  2.2428,  ...,  2.0658,  2.0068, -2.4183],\n",
      "         [ 2.1838,  2.2625,  2.2625,  ...,  2.0658,  2.0265, -2.4183],\n",
      "         ...,\n",
      "         [ 0.0401,  0.3744,  0.4924,  ..., -0.7269, -0.7859, -2.4183],\n",
      "         [ 0.3351,  0.4924,  0.3941,  ..., -0.6876, -0.8646, -2.4183],\n",
      "         [ 0.3351,  0.4728,  0.3941,  ..., -0.7662, -1.0809, -2.4183]],\n",
      "\n",
      "        [[ 2.4221,  2.4611,  2.5001,  ...,  2.3245,  2.3050, -2.2214],\n",
      "         [ 2.3635,  2.4025,  2.4416,  ...,  2.3050,  2.3245, -2.2214],\n",
      "         [ 2.3830,  2.4611,  2.4611,  ...,  2.3050,  2.3245, -2.2214],\n",
      "         ...,\n",
      "         [ 0.1784,  0.5100,  0.6661,  ..., -1.7727, -1.4995, -2.2214],\n",
      "         [ 0.4905,  0.6661,  0.5881,  ..., -1.7141, -1.6556, -2.2214],\n",
      "         [ 0.5296,  0.6661,  0.5881,  ..., -1.7727, -1.9482, -2.2214]]])\n",
      "Data Label: 9\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# TRAINING DATA\n",
    "\n",
    "# taking mean and std values from the book\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.Normalize(mean=(0.4914, 0.4822, 0.4465),\n",
    "                        std=(0.2023, 0.1994, 0.201)),\n",
    "])\n",
    "\n",
    "train_data_xform = CIFAR10(root=\"./train/\",\n",
    "                     train=True,\n",
    "                     transform=train_transform)\n",
    "\n",
    "data, label = train_data[16]\n",
    "print(f'Training data without transforms: {data}')\n",
    "print(f'Data Label: {label}')\n",
    "\n",
    "data, label = train_data_xform[16]\n",
    "print(f'Training data with transforms: {data}')\n",
    "print(f'Data Label: {label}')\n",
    "\n",
    "\n",
    "# TESTING DATA\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        (0.4914, 0.4822, 0.4465),\n",
    "        (0.2023, 0.1994, 0.2010))\n",
    "    ])\n",
    "\n",
    "test_data = CIFAR10(root=\"./test/\",\n",
    "                     train=False,\n",
    "                     transform=test_transform,\n",
    "                     download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`When you instantiate train_data the second time, with the transform, try without download=True. Look at the API. What does it say?`\n",
    "<p>If download is set to 'True', the data is downloaded to the root directory, otherwise it will verify the data has been downloaded. If the 'download' option is not included and the Dataset is not found, it will cause a runtime error.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`What is the difference between training and testing transforms? Training is supposed to ”see” more data variability and that is why we provide augmentations of the original data through transforms. Why do you think the test dataset has a different transform?`\n",
    "\n",
    "The training transform has augmentations such as horizontal flips and random crops whereas the testing data is unaltered aside from normalization. Keeping the two sets seperated like this helps simulate real-world variabiltiy and the model will make generalizations about unseen data. Augmenting the testing data the same way as the training data may lead to overly-optimistic results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Please do` <br>\n",
    "`data, label = train_data[index] in both cases (with and without transforms).`<br>\n",
    "`Why is your result different when you apply transforms?`\n",
    "\n",
    "Before transforms are applied, the data is raw. When accessing train_data[index], metadata is returned such as the color mode, size, and address in memory. When the data is processed with a transform, it's changed into a tensor so that it is readable by a machine learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Batching\n",
    "<p> I've noticed that bigger batch size results in faster training times, likely because it takes better advtange of GPU parallelism. However, it also leads to higher loss value. The larger batch size causes a smoother average since extreme or outlying datapoints have less influence over the loss value. The learning rate and the number of epochs has to be adjusted in order to get accurate results. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 3, 32, 32])\n",
      "torch.Size([512])\n"
     ]
    }
   ],
   "source": [
    "train_set, val_set = random_split(\n",
    "                      train_data_xform, \n",
    "                      [40000, 10000])\n",
    "\n",
    "batch_size = 512\n",
    "\n",
    "# Dataloader does all the work of shuffling data between batches and training cycles (epochs)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set,\n",
    "    batch_size,           # Bigger batch size results in faster training times, and higher memory usage\n",
    "    shuffle = True)\n",
    "\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_set,\n",
    "    batch_size,\n",
    "    shuffle = True)\n",
    "\n",
    "# create data batches\n",
    "data_batch, labels_batch = next(iter(train_loader))\n",
    "\n",
    "print(data_batch.size())\n",
    "print(labels_batch.size())\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data,\n",
    "    batch_size,\n",
    "    shuffle = False) # set shuffle to false for the testing data for repeatable results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thomas/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/thomas/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Layers: \n",
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "vgg16 = models.vgg16(pretrained=True)     # faster convergence on pre-trained models\n",
    "\n",
    "# Print layers of the neural network\n",
    "print(\"Neural Network Layers: \")\n",
    "print(vgg16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the Linear transformation layer with a new definition\n",
    "\"\"\"There are 10 classes in the CIFAR10 dataset, so 10 possible output features\"\"\"\n",
    "vgg16.classifier[-1] = nn.Linear(4096, 10)\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "model_vgg = vgg16.to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training\n",
    "\n",
    "<p> I spent too much time trying to debug the training loop when it kept crashing my laptop. Tried again on my desktop and it turned out my laptop just couldn't handle it The training loop took around 20-25 minutes to complete with the original parameters but I managed to get it down to around 6 minutes. It was fun playing around with this to get the loop to run in a more efficient way while trying to maintain around 80% accuracy </p> \n",
    "<br>\n",
    "Training: Find patters of a given data set <br>\n",
    "Validation: Tune hyperparameters and evaulate the model on a separate portion of the data set <br>\n",
    "Testing: Assess performance of the model with unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Epoch: 0 Training Loss: 1.0488099033319498\n",
      "VALIDATION\n",
      "Epoch: 0 Train Loss: 1.0488099033319498 Val Loss: 0.720560047030449\n",
      "TRAINING\n",
      "Epoch: 1 Training Loss: 0.6111336961577211\n",
      "VALIDATION\n",
      "Epoch: 1 Train Loss: 0.6111336961577211 Val Loss: 0.5401115983724594\n",
      "TRAINING\n",
      "Epoch: 2 Training Loss: 0.4940812150134316\n",
      "VALIDATION\n",
      "Epoch: 2 Train Loss: 0.4940812150134316 Val Loss: 0.4865541115403175\n",
      "TRAINING\n",
      "Epoch: 3 Training Loss: 0.43345013449463665\n",
      "VALIDATION\n",
      "Epoch: 3 Train Loss: 0.43345013449463665 Val Loss: 0.5707439735531807\n",
      "TRAINING\n",
      "Epoch: 4 Training Loss: 0.39824442131609855\n",
      "VALIDATION\n",
      "Epoch: 4 Train Loss: 0.39824442131609855 Val Loss: 0.4622436985373497\n",
      "TRAINING\n",
      "Epoch: 5 Training Loss: 0.35303788132305386\n",
      "VALIDATION\n",
      "Epoch: 5 Train Loss: 0.35303788132305386 Val Loss: 0.42820024490356445\n",
      "TRAINING\n",
      "Epoch: 6 Training Loss: 0.3112582058846196\n",
      "VALIDATION\n",
      "Epoch: 6 Train Loss: 0.3112582058846196 Val Loss: 0.3967589601874352\n",
      "TRAINING\n",
      "Epoch: 7 Training Loss: 0.2883705504332917\n",
      "VALIDATION\n",
      "Epoch: 7 Train Loss: 0.2883705504332917 Val Loss: 0.37609817534685136\n",
      "TRAINING\n",
      "Epoch: 8 Training Loss: 0.26044184686262395\n",
      "VALIDATION\n",
      "Epoch: 8 Train Loss: 0.26044184686262395 Val Loss: 0.37260369658470155\n",
      "TRAINING\n",
      "Epoch: 9 Training Loss: 0.24151265809807596\n",
      "VALIDATION\n",
      "Epoch: 9 Train Loss: 0.24151265809807596 Val Loss: 0.37985303103923795\n",
      "TRAINING\n",
      "Epoch: 10 Training Loss: 0.2263525920578196\n",
      "VALIDATION\n",
      "Epoch: 10 Train Loss: 0.2263525920578196 Val Loss: 0.412492199242115\n",
      "TRAINING\n",
      "Epoch: 11 Training Loss: 0.21956173849256733\n",
      "VALIDATION\n",
      "Epoch: 11 Train Loss: 0.21956173849256733 Val Loss: 0.37677881121635437\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 12\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model_vgg.parameters(),\n",
    "                      lr=0.010, \n",
    "                      momentum=0.9)\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    # TRAINING\n",
    "    train_loss = 0.0\n",
    "    model_vgg.train()\n",
    "    print(\"TRAINING\") \n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(device) \n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()   # forget errors of previous pass, let's start fresh\n",
    "\n",
    "        outputs = model_vgg(inputs)\n",
    "        loss = criterion(outputs, labels)   # compute loss\n",
    "        \n",
    "        loss.backward()         # backpropegation; compute gradient\n",
    "        \n",
    "        optimizer.step()        # adjust parameters based on gradient \n",
    "\n",
    "        train_loss += loss.item()\n",
    "    print(\"Epoch: {} Training Loss: {}\".format(epoch, \n",
    "                  train_loss/len(train_loader)))\n",
    "    \n",
    "    # VALIDATION\n",
    "    val_loss = 0.0\n",
    "    model_vgg.eval()\n",
    "    print(\"VALIDATION\")\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model_vgg(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        val_loss += loss.item()\n",
    "    print(\"Epoch: {} Train Loss: {} Val Loss: {}\".format(\n",
    "                  epoch, \n",
    "                  train_loss/len(train_loader), \n",
    "                  val_loss/len(val_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 512\n",
      "Test Accuracy: 0.8656250238418579\n"
     ]
    }
   ],
   "source": [
    "num_correct = 0.0\n",
    "\n",
    "for x_test_batch, y_test_batch in test_loader:\n",
    "\n",
    "    model_vgg.eval()\n",
    "    y_test_batch = y_test_batch.to(device)\n",
    "    x_test_batch = x_test_batch.to(device)\n",
    "\n",
    "    y_pred_batch = model_vgg(x_test_batch)\n",
    "    _, predicted = torch.max(y_pred_batch, 1)\n",
    "    num_correct += (predicted == y_test_batch).float().sum()\n",
    "\n",
    "vgg_accuracy = num_correct/(len(test_loader)*test_loader.batch_size)\n",
    "\n",
    "print(len(test_loader), test_loader.batch_size)\n",
    "print(\"Test Accuracy: {}\".format(vgg_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG16 vs LeNet5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LeNet class definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5) # <1>\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, int(x.nelement() / x.shape[0]))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "device = \"cuda\"\n",
    "model_lenet = LeNet5().to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LeNet training loop \n",
    "<p> Using same parameters as the VGG test </p>\n",
    "<p> Overfitting is a problem here </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Loss: 2.286281679250017\n",
      "Epoch: 0 Train Loss: 0.21956173849256733 Val Loss: 2.2244025588035585\n",
      "Epoch: 1 Loss: 2.100385238852682\n",
      "Epoch: 1 Train Loss: 0.21956173849256733 Val Loss: 1.9348701655864715\n",
      "Epoch: 2 Loss: 1.851892442642888\n",
      "Epoch: 2 Train Loss: 0.21956173849256733 Val Loss: 1.7533231496810913\n",
      "Epoch: 3 Loss: 1.7140138224710393\n",
      "Epoch: 3 Train Loss: 0.21956173849256733 Val Loss: 1.7000286281108856\n",
      "Epoch: 4 Loss: 1.6216940608205674\n",
      "Epoch: 4 Train Loss: 0.21956173849256733 Val Loss: 1.5980807721614838\n",
      "Epoch: 5 Loss: 1.5640281785892536\n",
      "Epoch: 5 Train Loss: 0.21956173849256733 Val Loss: 1.5401451289653778\n",
      "Epoch: 6 Loss: 1.518982716753513\n",
      "Epoch: 6 Train Loss: 0.21956173849256733 Val Loss: 1.485310137271881\n",
      "Epoch: 7 Loss: 1.4623648275302936\n",
      "Epoch: 7 Train Loss: 0.21956173849256733 Val Loss: 1.5073103308677673\n",
      "Epoch: 8 Loss: 1.4193265951132472\n",
      "Epoch: 8 Train Loss: 0.21956173849256733 Val Loss: 1.4073999166488647\n",
      "Epoch: 9 Loss: 1.3792128215862225\n",
      "Epoch: 9 Train Loss: 0.21956173849256733 Val Loss: 1.4422661423683167\n",
      "Epoch: 10 Loss: 1.3484251408637324\n",
      "Epoch: 10 Train Loss: 0.21956173849256733 Val Loss: 1.3971993446350097\n",
      "Epoch: 11 Loss: 1.3166957173166396\n",
      "Epoch: 11 Train Loss: 0.21956173849256733 Val Loss: 1.3951956927776337\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model_lenet.parameters(),\n",
    "                      lr=0.010, \n",
    "                      momentum=0.9)\n",
    "\n",
    "# TRAINING\n",
    "for epoch in range(N_EPOCHS):\n",
    "    epoch_loss = 0.0\n",
    "    model_lenet.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(device) \n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()   # forget errors of previous pass, let's start fresh\n",
    "\n",
    "        outputs = model_lenet(inputs)\n",
    "        loss = criterion(outputs, labels)   # compute loss\n",
    "        \n",
    "        loss.backward()         # backpropegation; compute gradient\n",
    "        \n",
    "        optimizer.step()        # adjust parameters based on gradient \n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "    print(\"Epoch: {} Loss: {}\".format(epoch, \n",
    "                  epoch_loss/len(train_loader)))\n",
    "    \n",
    "    #VALIDATION\n",
    "    val_loss = 0.0\n",
    "    model_lenet.eval()\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model_lenet(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        val_loss += loss.item()\n",
    "    print(\"Epoch: {} Train Loss: {} Val Loss: {}\".format(\n",
    "                  epoch, \n",
    "                  train_loss/len(train_loader), \n",
    "                  val_loss/len(val_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 512\n",
      "LeNet5 Test Accuracy: 0.5376953482627869\n",
      "VGG16 Test Accuracy: 0.8656250238418579\n"
     ]
    }
   ],
   "source": [
    "num_correct = 0.0\n",
    "\n",
    "for x_test_batch, y_test_batch in test_loader:\n",
    "\n",
    "    model_lenet.eval()\n",
    "    y_test_batch = y_test_batch.to(device)\n",
    "    x_test_batch = x_test_batch.to(device)\n",
    "\n",
    "    y_pred_batch = model_lenet(x_test_batch)\n",
    "    _, predicted = torch.max(y_pred_batch, 1)\n",
    "    num_correct += (predicted == y_test_batch).float().sum()\n",
    "\n",
    "lenet_accuracy = num_correct/(len(test_loader)*test_loader.batch_size)\n",
    "\n",
    "print(len(test_loader), test_loader.batch_size)\n",
    "print(\"LeNet5 Test Accuracy: {}\".format(lenet_accuracy))\n",
    "print(\"VGG16 Test Accuracy: {}\".format(vgg_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Please compare these two performances on CIFAR10. Why is one better than another?`\n",
    "<p> VGG16 took longer but was much more accurate. LeNet5 was faster but did not have accurate results. This is because VGG16 is a deeper neural network with 16 weight layers, 13 convolution layers, 5 max pooling layers, and 3 dense layers. This allows VGG16 to find more complex patterns compared to LeNet5's 2 convolution layers and 3 linear layers. </p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
