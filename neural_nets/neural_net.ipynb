{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F07HKWTk8VBx"
      },
      "source": [
        "# PyTorch Tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 233,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4uafWiZ8cVZ",
        "outputId": "059df7e2-413a-4330-8e48-4380374b1925"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f6506beaf30>"
            ]
          },
          "execution_count": 233,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "torch.manual_seed(0) # for reproducability"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5S-vhnqa8v1p"
      },
      "source": [
        "## Tensor Init"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 234,
      "metadata": {
        "id": "JLNnbQTI8Rav"
      },
      "outputs": [],
      "source": [
        "arr = [1,2]\n",
        "tensor = torch.tensor(arr)\n",
        "val = 2.0\n",
        "tensor = torch.tensor(val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 235,
      "metadata": {
        "id": "UjQX09lMWloJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "np_arr = np.array([1,2])\n",
        "x_t = torch.from_numpy(np_arr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 236,
      "metadata": {
        "id": "nAuimXkkW25x"
      },
      "outputs": [],
      "source": [
        "zeros_t = torch.zeros((2,3)) # Returns 2x3 tensor of zeros\n",
        "ones_t = torch.ones((2,3)) # Returns 2x3 tensor of ones\n",
        "rand_t = torch.randn((2,3)) # Returns 2x3 tensor of random numbers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyaxqW2r843z"
      },
      "source": [
        "## Tensor Attributes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 237,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVdTfSyb8rzG",
        "outputId": "f4188b9e-394e-4515-b71e-de3ba87e10ac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 3])"
            ]
          },
          "execution_count": 237,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "zeros_t.shape # Returns torch.Size([2, 3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 238,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3JD0VX6838x",
        "outputId": "9a01db1f-237d-4c99-8c73-686c3126b570"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "execution_count": 238,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_t = torch.tensor(2.0)\n",
        "x_t.dtype # Returns torch.float32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 239,
      "metadata": {
        "id": "LsAfVEf2BssB"
      },
      "outputs": [],
      "source": [
        "arr = [1,2]\n",
        "x_t = torch.tensor(arr, dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 240,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Re9-RKyVBvm1",
        "outputId": "d3bdbe09-821e-4de6-a971-044e37181b83"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "execution_count": 240,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_t.device # Returns device(type='cpu') by default"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 241,
      "metadata": {
        "id": "Q4nLgr0hBypK"
      },
      "outputs": [],
      "source": [
        "# PyTorch will use GPU if it's available\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "arr = [1,2]\n",
        "x_t = torch.tensor(arr, dtype=torch.float32, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 242,
      "metadata": {
        "id": "HMvlzUQFB1m5"
      },
      "outputs": [],
      "source": [
        "x_t = x_t.to(device, dtype=torch.int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SadKNln871T"
      },
      "source": [
        "## Tensor Operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 243,
      "metadata": {
        "id": "gVmKbPR089YB"
      },
      "outputs": [],
      "source": [
        "c = 10\n",
        "x_t = x_t*c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 244,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NJkZzRTBKzi",
        "outputId": "b8dd5219-0cdb-4690-96c8-412accb956c3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1., 1.]])"
            ]
          },
          "execution_count": 244,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x1_t = torch.zeros((1,2))\n",
        "x2_t = torch.ones((1,2))\n",
        "x1_t + x2_t\n",
        "# returns tensor([[1., 1.]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 245,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQdOD6J7BNjW",
        "outputId": "d5e6d950-f1a2-4741-87aa-eb54c2a4dbac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 9, 12, 15],\n",
              "        [19, 26, 33]])"
            ]
          },
          "execution_count": 245,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x1_t = torch.tensor([[1,2],[3,4]])\n",
        "x2_t = torch.tensor([[1,2,3],[4,5,6]])\n",
        "torch.matmul(x1_t, x2_t) # Returns tensor([[9,12,15],[19,26,33]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 246,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1C5gv5sWBR6p",
        "outputId": "c7c1df69-10dd-4ab1-952e-0c95fd4121ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[3, 7, 9],\n",
            "         [2, 4, 5]],\n",
            "\n",
            "        [[8, 6, 2],\n",
            "         [3, 9, 1]]])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor(4)"
            ]
          },
          "execution_count": 246,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "i,j,k = 0,1,1\n",
        "x3_t = torch.tensor([[[3,7,9],[2,4,5]],[[8,6,2],[3,9,1]]])\n",
        "print(x3_t)\n",
        "# out:\n",
        "# tensor([[[3, 7, 9],\n",
        "#          [2, 4, 5]],\n",
        "#         [[8, 6, 2],\n",
        "#          [3, 9, 1]]])\n",
        "\n",
        "x3_t[i,j,k]\n",
        "# out:\n",
        "# tensor(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 247,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XMe_Ls7BW1A",
        "outputId": "b694d7cb-b992-4483-8cb3-466e68f80227"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[3, 7, 9],\n",
              "        [2, 4, 5]])"
            ]
          },
          "execution_count": 247,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x3_t[0] # Returns the matrix at position 0 in tensor\n",
        "x3_t[0,:,:] # Also returns the matrix at position 0 in tensor!\n",
        "# out:\n",
        "# tensor([[3, 7, 9],\n",
        "#         [2, 4, 1]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 248,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1N7VBdhBZqt",
        "outputId": "53e4693d-421b-4327-a7cd-3e3903770527"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[2, 4, 5]])"
            ]
          },
          "execution_count": 248,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x3_t[0,1:3,:]\n",
        "# returns tensor([[2, 4, 5]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 249,
      "metadata": {
        "id": "ne5lWR2JBb-a"
      },
      "outputs": [],
      "source": [
        "x3_t[0,1,2] = 1\n",
        "# out:\n",
        "# tensor([[[3, 7, 9],\n",
        "#          [2, 4, 1]],\n",
        "\n",
        "#         [[8, 6, 2],\n",
        "#          [3, 9, 1]]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 250,
      "metadata": {
        "id": "bKpC3twXBeBe"
      },
      "outputs": [],
      "source": [
        "x_t = torch.randn(2,3,4)\n",
        "sub_tensor = torch.randn(2,4)\n",
        "x_t[0,1:3,:] = sub_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 251,
      "metadata": {
        "id": "7WyDzjhvBiol"
      },
      "outputs": [],
      "source": [
        "x_t[0,1:3,:] = 1\n",
        "sub_tensor = torch.randn(1,4)\n",
        "x_t[0,1:3,:] = sub_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MD8EA1gw9ApD"
      },
      "source": [
        "#Gradients in PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 252,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xz6ksmHL9DRD",
        "outputId": "18740ec9-73a1-49cf-8920-2c43a108d204"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(4.), tensor(6.), tensor(3.))"
            ]
          },
          "execution_count": 252,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.tensor(2.0, requires_grad=True)\n",
        "y = torch.tensor(3.0, requires_grad=True)\n",
        "z = torch.tensor(1.5, requires_grad=True)\n",
        "f = x**2+y**2+z**2\n",
        "f.backward()\n",
        "x.grad, y.grad, z.grad\n",
        "# out:\n",
        "# (tensor(4.), tensor(6.), tensor(3.))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQ-2brO89ES0"
      },
      "source": [
        "# The PyTorch nn module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 253,
      "metadata": {
        "id": "yDw2Kvg49GgO"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define Neural Network Learning Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<p> Initialize weight matrix for feed-forward neural network</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 254,
      "metadata": {
        "id": "gkoyexGYAC7Q"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([-2.8447e-01, -9.3781e-02,  5.3478e-04, -2.6831e-01, -3.1255e-01,\n",
            "        -8.0501e-01,  9.6301e-02, -3.2780e-01,  1.0920e-01, -2.1979e-01],\n",
            "       grad_fn=<AddBackward0>)\n"
          ]
        }
      ],
      "source": [
        "in_dim, out_dim = 256, 10       # input vector dimension, output vector dimension\n",
        "vec = torch.randn(256)          # return tensor of random numbers\n",
        "layer = nn.Linear(in_dim, out_dim, bias=True)   # Linear() is an abstraction of the next cell\n",
        "out = layer(vec)\n",
        "\n",
        "print(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<p> Manually compute the weights and bias </p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 255,
      "metadata": {
        "id": "172mP5cuAFyd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ -6.5247,  -4.6500,  -0.5075,  -5.0551,  -8.8740, -10.0773,   3.9237,\n",
            "         -10.9351,  -8.6859,  -9.2785],\n",
            "        [ -6.5247,  -4.6500,  -0.5075,  -5.0551,  -8.8740, -10.0773,   3.9237,\n",
            "         -10.9351,  -8.6859,  -9.2785],\n",
            "        [ -6.5247,  -4.6500,  -0.5075,  -5.0551,  -8.8740, -10.0773,   3.9237,\n",
            "         -10.9351,  -8.6859,  -9.2785],\n",
            "        [ -6.5247,  -4.6500,  -0.5075,  -5.0551,  -8.8740, -10.0773,   3.9237,\n",
            "         -10.9351,  -8.6859,  -9.2785],\n",
            "        [ -6.5247,  -4.6500,  -0.5075,  -5.0551,  -8.8740, -10.0773,   3.9237,\n",
            "         -10.9351,  -8.6859,  -9.2785],\n",
            "        [ -6.5247,  -4.6500,  -0.5075,  -5.0551,  -8.8740, -10.0773,   3.9237,\n",
            "         -10.9351,  -8.6859,  -9.2785],\n",
            "        [ -6.5247,  -4.6500,  -0.5075,  -5.0551,  -8.8740, -10.0773,   3.9237,\n",
            "         -10.9351,  -8.6859,  -9.2785],\n",
            "        [ -6.5247,  -4.6500,  -0.5075,  -5.0551,  -8.8740, -10.0773,   3.9237,\n",
            "         -10.9351,  -8.6859,  -9.2785],\n",
            "        [ -6.5247,  -4.6500,  -0.5075,  -5.0551,  -8.8740, -10.0773,   3.9237,\n",
            "         -10.9351,  -8.6859,  -9.2785],\n",
            "        [ -6.5247,  -4.6500,  -0.5075,  -5.0551,  -8.8740, -10.0773,   3.9237,\n",
            "         -10.9351,  -8.6859,  -9.2785]])\n"
          ]
        }
      ],
      "source": [
        "W = torch.rand(10,256)\n",
        "b = torch.zeros(10,1)\n",
        "out = torch.matmul(W, vec) + b\n",
        "\n",
        "print(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<p> Neural network to represent W2(W1 * x +b1) + b2 </p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 256,
      "metadata": {
        "id": "mtNoAAE6AKcv"
      },
      "outputs": [],
      "source": [
        "in_dim, feature_dim, out_dim = 784, 256, 10\n",
        "vec = torch.randn(784)\n",
        "layer1 = nn.Linear(in_dim, feature_dim, bias=True)\n",
        "layer2 = nn.Linear(feature_dim, out_dim, bias=True)\n",
        "out = layer2(layer1(vec))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<p> Introduce non-linearity with ReLU </p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 257,
      "metadata": {
        "id": "MLRoVWgzANnr"
      },
      "outputs": [],
      "source": [
        "relu = nn.ReLU()\n",
        "out = layer2(relu(layer1(vec)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Example class of the neural network that was just defined"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 258,
      "metadata": {
        "id": "6bBeoIeMAR39"
      },
      "outputs": [],
      "source": [
        "class BaseClassifier(nn.Module):\n",
        "  def __init__(self, in_dim, feature_dim, out_dim):\n",
        "    super(BaseClassifier, self).__init__()\n",
        "    self.layer1 = nn.Linear(in_dim, feature_dim, bias=True)\n",
        "    self.layer2 = nn.Linear(feature_dim, out_dim, bias=True)\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "# Feed forward\n",
        "  def forward(self, x):\n",
        "    x = self.layer1(x)\n",
        "    x = self.relu(x)\n",
        "    out = self.layer2(x)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 259,
      "metadata": {
        "id": "snixCbP3Abuk"
      },
      "outputs": [],
      "source": [
        "no_examples = 10\n",
        "in_dim, feature_dim, out_dim = 784, 256, 10\n",
        "x = torch.randn((no_examples, in_dim))\n",
        "classifier = BaseClassifier(in_dim, feature_dim, out_dim)\n",
        "out = classifier(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 260,
      "metadata": {
        "id": "vg3QNC3TAe9D"
      },
      "outputs": [],
      "source": [
        "loss = nn.CrossEntropyLoss()\n",
        "target = torch.tensor([0,3,2,8,2,9,3,7,1,6])\n",
        "computed_loss = loss(out, target)\n",
        "computed_loss.backward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 261,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1p_J0g4ut3F",
        "outputId": "d7c3f383-6685-4085-d72c-7f8585525e4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([256, 784])\n",
            "torch.Size([256])\n",
            "torch.Size([10, 256])\n",
            "torch.Size([10])\n"
          ]
        }
      ],
      "source": [
        "for p in classifier.parameters():\n",
        "  print(p.shape)\n",
        "\n",
        "# out:\n",
        "# torch.Size([256, 784])\n",
        "# torch.Size([256])\n",
        "# torch.Size([10, 256])\n",
        "# torch.Size([10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 262,
      "metadata": {
        "id": "DGb30o-VAlyz"
      },
      "outputs": [],
      "source": [
        "from torch import optim\n",
        "\n",
        "lr = 1e-3\n",
        "optimizer = optim.SGD(classifier.parameters(), lr=lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 263,
      "metadata": {
        "id": "WsVMNnSnAoey"
      },
      "outputs": [],
      "source": [
        "optimizer.step() # Updates parameters via SGD\n",
        "optimizer.zero_grad() # Zeroes out gradients between minibatches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCgfC7oM9H4I"
      },
      "source": [
        "# PyTorch Datasets and Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 264,
      "metadata": {
        "id": "e4eOrEzr9Nni"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 265,
      "metadata": {
        "id": "gRgBTOpX0sRp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "labels = np.array([2, 0, 4, 1])\n",
        "np.save('labels',labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 266,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvu8i9QX06LN",
        "outputId": "aa6cfb48-a801-4b2f-cc70-b89651d5d564"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([2, 0, 4, 1])"
            ]
          },
          "execution_count": 266,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "labels_1 = np.load('labels.npy')\n",
        "labels_1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGRIi9Cpgqf0"
      },
      "source": [
        "### First download files for use in custom ImageDataset example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 267,
      "metadata": {
        "id": "myX-sYoDeL-0"
      },
      "outputs": [],
      "source": [
        "!mkdir -p data\n",
        "!mkdir -p data/train\n",
        "\n",
        "!wget -O data/train/img_0.jpg -nc -q https://github.com/darksigma/Fundamentals-of-Deep-Learning-Book/raw/master/ch05_implementing_nn_pytorch/data/train/img_0.jpg\n",
        "!wget -O data/train/img_1.jpg -nc -q https://github.com/darksigma/Fundamentals-of-Deep-Learning-Book/raw/master/ch05_implementing_nn_pytorch/data/train/img_1.jpg\n",
        "!wget -O data/train/img_2.jpg -nc -q https://github.com/darksigma/Fundamentals-of-Deep-Learning-Book/raw/master/ch05_implementing_nn_pytorch/data/train/img_2.jpg\n",
        "!wget -O data/train/img_3.jpg -nc -q https://github.com/darksigma/Fundamentals-of-Deep-Learning-Book/raw/master/ch05_implementing_nn_pytorch/data/train/img_3.jpg\n",
        "!wget -O data/train/labels.npy -nc -q https://github.com/darksigma/Fundamentals-of-Deep-Learning-Book/raw/master/ch05_implementing_nn_pytorch/data/train/labels.npy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 268,
      "metadata": {
        "id": "3Cy4e5v4-nJY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "\n",
        "class ImageDataset(Dataset):\n",
        "  def __init__(self, img_dir, label_file):\n",
        "    super(ImageDataset, self).__init__()\n",
        "    self.img_dir = img_dir\n",
        "    self.labels = torch.tensor(np.load(label_file, allow_pickle=True))\n",
        "    self.transforms = transforms.ToTensor()\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    img_pth = os.path.join(self.img_dir, \"img_{}.jpg\".format(idx))\n",
        "    img = Image.open(img_pth)\n",
        "    img = self.transforms(img).flatten()\n",
        "    label = self.labels[idx]\n",
        "    return {\"data\":img, \"label\":label}\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 269,
      "metadata": {
        "id": "9P5g3VFg-uwc"
      },
      "outputs": [],
      "source": [
        "train_dataset = ImageDataset(img_dir='./data/train/',\n",
        "                             label_file='./data/train/labels.npy')\n",
        "\n",
        "train_loader = DataLoader(train_dataset, \n",
        "                          batch_size=4, \n",
        "                          shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 270,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "245Aiav8-zdU",
        "outputId": "78e046bf-5839-4e07-c564-94f32d715d3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
            "tensor([1, 2, 0, 4])\n"
          ]
        }
      ],
      "source": [
        "for minibatch in train_loader:\n",
        "  data, labels = minibatch['data'], minibatch['label']\n",
        "  print(data)\n",
        "  print(labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhIl1Li_9Pe7"
      },
      "source": [
        "# Building the MNIST Classifer in PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 271,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEaA22tUmZnJ",
        "outputId": "21b628a4-f380-4706-d048-f88b7e1c63d8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f6506beaf30>"
            ]
          },
          "execution_count": 271,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import optim\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "# For reproducability\n",
        "torch.manual_seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 272,
      "metadata": {
        "id": "uaGRqlxP9VCs"
      },
      "outputs": [],
      "source": [
        "class BaseClassifier(nn.Module):\n",
        "  def __init__(self, in_dim, feature_dim, out_dim):\n",
        "    super(BaseClassifier, self).__init__()\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Linear(in_dim, feature_dim, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(feature_dim, out_dim, bias=True)\n",
        "    )\n",
        "    \n",
        "  def forward(self, x):\n",
        "    return self.classifier(x)\n",
        "    \n",
        "\n",
        "# Load in MNIST dataset from PyTorch\n",
        "train_dataset = MNIST(\".\", train=True, \n",
        "                      download=True, transform=ToTensor())\n",
        "test_dataset = MNIST(\".\", train=False, \n",
        "                     download=True, transform=ToTensor())\n",
        "train_loader = DataLoader(train_dataset, \n",
        "                          batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, \n",
        "                         batch_size=64, shuffle=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Qpb4Tb44oho"
      },
      "source": [
        "# NOTE: \n",
        "The train() function below will take approx. 5-6 minutes to run with epochs = 40."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 273,
      "metadata": {
        "id": "m0P-MpP-9lfl"
      },
      "outputs": [],
      "source": [
        "# Instantiate model, optimizer, and hyperparameter(s)\n",
        "in_dim, feature_dim, out_dim = 784, 256, 10\n",
        "lr=1e-3\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "epochs=40\n",
        "classifier = BaseClassifier(in_dim, feature_dim, out_dim)\n",
        "optimizer = optim.SGD(classifier.parameters(), lr=lr)\n",
        "\n",
        "def train(classifier=classifier,\n",
        "          optimizer=optimizer,\n",
        "          epochs=epochs,\n",
        "          loss_fn=loss_fn):\n",
        "\n",
        "  classifier.train()\n",
        "  loss_lt = []\n",
        "  for epoch in range(epochs):\n",
        "    running_loss = 0.0\n",
        "    for minibatch in train_loader:\n",
        "      data, target = minibatch\n",
        "      data = data.flatten(start_dim=1)\n",
        "      out = classifier(data)\n",
        "      computed_loss = loss_fn(out, target)\n",
        "      computed_loss.backward()\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "      # Keep track of sum of loss of each minibatch\n",
        "      running_loss += computed_loss.item()\n",
        "    loss_lt.append(running_loss/len(train_loader))\n",
        "    print(\"Epoch: {} train loss: {}\".format(epoch+1, running_loss/len(train_loader)))\n",
        "\n",
        "  plt.plot([i for i in range(1,epochs+1)], loss_lt)\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Training Loss\")\n",
        "  plt.title(\n",
        "      \"MNIST Training Loss: optimizer {}, lr {}\".format(\"SGD\", lr))\n",
        "  plt.show()\n",
        "\n",
        "  # Save state to file as checkpoint\n",
        "  torch.save(classifier.state_dict(), 'mnist.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 274,
      "metadata": {
        "id": "pMiCCu8Nln8w"
      },
      "outputs": [],
      "source": [
        "def test(classifier=classifier, \n",
        "          loss_fn = loss_fn):\n",
        "  classifier.eval()\n",
        "  accuracy = 0.0\n",
        "  computed_loss = 0.0\n",
        "\n",
        "  with torch.no_grad():\n",
        "      for data, target in test_loader:\n",
        "          data = data.flatten(start_dim=1)\n",
        "          out = classifier(data)\n",
        "          _, preds = out.max(dim=1)\n",
        "\n",
        "          # Get loss and accuracy\n",
        "          computed_loss += loss_fn(out, target)\n",
        "          accuracy += torch.sum(preds==target)\n",
        "          \n",
        "      print(\"Test loss: {}, test accuracy: {}\".format(\n",
        "          computed_loss.item()/(len(test_loader)*64), accuracy*100.0/(len(test_loader)*64)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 275,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 989
        },
        "id": "g79BDGlp85Uc",
        "outputId": "97059680-2635-47c1-e9ee-a56aaf86c5f6"
      },
      "outputs": [],
      "source": [
        "#train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 276,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3UsxvLd874B",
        "outputId": "50fd10a0-75d5-4321-89da-89216ebf4d0b"
      },
      "outputs": [],
      "source": [
        "#test()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualize Flattened Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 277,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKAAAACgCAYAAACLz2ctAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAFEUlEQVR4nO3dvy6saxTH8TMYZhgSQiKhmp5Op6OViAtQuAilS3AVbkInCnqdRmQSjT8RY8YYDLs53foV67D3+dmP76dc8c68e+e3V6z9PM/7Vj4+Pj7+AUyG3DeAn40AwooAwooAwooAwooAwooAwooAwooAwmok+4OVSuVP3seX1ev1UOv1eqlrJyYmQq3b7aauHR0dDbW3t7dQe39/T31eKbILbHRAWBFAWBFAWBFAWFWy27G++xCi1Gq1UHt5eQm17IBQrVZT1w4Gg9TnlYwhBH8FAggrAggrAgir9ErI30gNA2poUMOFWuH4yuqIGn5AB4QZAYQVAYQVAYRVMUPI0FD8t5RdkVA/1+/3U9fOzs6G2u3tbepa0AFhRgBhRQBhRQBhVcwQMjIS/yhqS5BaCclux1pdXQ217e3tUDs4OAi14+Pj1Hf8NHRAWBFAWBFAWBFAWBUzhGS3O6mzLWqAUasjMzMzobazsxNqzWYz1NbX11P399PQAWFFAGFFAGFFAGFVzBCSpVZH1BDy+voaaqenp6F2dXUVagsLC5+8u5+HDggrAggrAggrAgirooeQRqMRap1OJ9TUo3zVYfW5ublQUwNM9tHAoAPCjADCigDCigDCqpghRD2RSg0c2SdXqZWQ5+fnUFMH4tV7QqDRAWFFAGFFAGFFAGFVzBCSPROiBoTh4eFQU9u2NjY2Qm1+fj7U2u126l5AB4QZAYQVAYQVAYRVMUOIog6hqydhZVdHlpeXU9+rVkyg0QFhRQBhRQBhRQBhVcwQogaO7Fu7s6sorVYrdS1DSB4dEFYEEFYEEFYEEFbFDCHZgUMdJFdbtNTPnZychJrayjU1NZW6F9ABYUYAYUUAYUUAYVXMEJKlDpIragi5vr7+rd8BOiDMCCCsCCCsCCCsihlC1C/+6vxHdsWk3++H2tLSUqipbWDdbjf1HaADwowAwooAwooAwqqYIUQNHNmtV9nzJGtra6Gmhh/1edDogLAigLAigLAigLAqZghR6vV6qD0+Pn76WjXUKLVaLdTUiw5vbm5CbXp6OtTu7+9T35ul7s91mJ4OCCsCCCsCCCsCCKuihxA1cKiD5OqXcrWlanx8PNTUINFsNkNtb28v1HZ3d0MtO3CoP4dalcm+dNGFDggrAggrAggrAgiroocQRW2zyj6iV1ErF2rFZHFxMdSyb1ZXqzK9Xi/UBoPBp691oQPCigDCigDCigDCqpghRJ3DUCsD6hd1dZ5EOTo6CrWtra3UdxweHoaaWqWoVquh9pWnbakXMTKEAP8igLAigLAigLAqZghRKxxqGFDGxsZCTT0d6+LiItQ6nU7qO87OzkJNbalSg4mqKerzsn8HLnRAWBFAWBFAWBFAWBUzhGSp7UlZm5ubodZoNELt8vIy1M7Pz0PtKwPC5ORkqKkzMGpI+k7DCh0QVgQQVgQQVgQQVsUMIdnH7Kpa9qB29k3orVYr1O7u7lLXZg+cZ9938t3RAWFFAGFFAGFFAGFVzBCiVjienp5CTQ0c2e1Y+/v7obayshJqDw8PqftTZzPUMPWVLVpqcGq326lr/w90QFgRQFgRQFgRQFhVPpL/pc4L+PBfZFdq6ICwIoCwIoCwIoCwIoCwIoCwIoCwIoCwIoCwIoCwIoCwIoCwIoCwIoCwIoCwIoCwIoCwIoCwIoCwSh9ML+VpTPhe6ICwIoCwIoCwIoCwIoCwIoCwIoCwIoCwIoCw+gUXnGk4DJl4CQAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 140x140 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "[(0.0, 28.0), (28.0, 0.0), None]"
            ]
          },
          "execution_count": 277,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "from torch import optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "ndata=data.view(4,28,28).detach().numpy()\n",
        "print(data)\n",
        "print(type(ndata))\n",
        "scale = 5\n",
        "\n",
        "im_data = ndata[0]\n",
        "\n",
        "print(type(im_data))\n",
        "\n",
        "dpi = matplotlib.rcParams['figure.dpi']\n",
        "height, width = im_data.shape\n",
        "figsize = scale * width / float(dpi), scale * height / float(dpi)\n",
        "\n",
        "fig = plt.figure(figsize=figsize)\n",
        "ax = fig.add_axes([0, 0, 1, 1])\n",
        "# Hide spines, ticks, etc.\n",
        "ax.axis('off')\n",
        "ax.imshow(im_data, vmin=0, vmax=1, cmap='gray')\n",
        "plt.show()\n",
        "ax.set(xlim=[0, width], ylim=[height, 0], aspect=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Principal Component Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<p> Normalize the data</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 278,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.0\n",
            "1.0\n",
            "0.0\n",
            "0.003921569\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# check minimum and maximum values of the image data\n",
        "print(np.min(ndata))\n",
        "print(np.max(ndata))\n",
        "\n",
        "# normalize image data\n",
        "ndata = ndata/255\n",
        "\n",
        "# check minimum and maximum values of the image data again\n",
        "print(np.min(ndata))\n",
        "print(np.max(ndata))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<p> Flatten and reshape data </p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 279,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(4, 28, 28)\n"
          ]
        }
      ],
      "source": [
        "print(ndata.shape)\n",
        "ndata_flat = ndata.reshape(-1,3136)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<p> Use PCA to reduce the dimensionality of the data from a (4, 28, 28) tensor to essentially a single point containing 90% of the data </p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 280,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/thomas/.local/lib/python3.10/site-packages/sklearn/decomposition/_pca.py:541: RuntimeWarning: invalid value encountered in divide\n",
            "  explained_variance_ = (S**2) / (n_samples - 1)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(1, 1)"
            ]
          },
          "execution_count": 280,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pca = PCA(0.9)\n",
        "pca.fit(ndata_flat)\n",
        "\n",
        "data = pca.transform(ndata_flat)\n",
        "\n",
        "data.shape"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Ch05_PyTorch.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
