{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4\n",
    "<p> Thomas Dougherty <br>\n",
    "10-14-2023 </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`What is transfer learning? Look it up, and write how you understood it.`\n",
    "<p> Transfer learning is the act of training a model for one task (taking a pretrained model) and fine tuning it for another specific task. Transfer learning is a more efficient way of training neural networks because it allows them to use knowledge from the previous task while working with less labeled data. </br>\n",
    "\n",
    "It's like going from a riding a mountain bike to learning how to ride a motorized dirt bike. All the time spent on a mountain bike taught you balance, cornering technique, and riding over rough terrain. Since those previous skills don't have to be learned again, you can focus on things like throttle control and riding at high speed giving you a headstart on the learning process. </p> </br>\n",
    "\n",
    "`Explain where the differences are that make the loss plot different between the first two notebooks.`\n",
    "1. neaclass2 is using a pretrained resnet18 model whereas neaclass1 is using a newly instantiated resnet18 model. This gives it a head start in the training process.\n",
    "</br>\n",
    "2. neaclass2 has learning rate scheduler. By slowing incrementally slowing down the learning rate over a period of epochs, the model will find the simple patterns first then \"zero in\" on finding complex patterns.\n",
    "</br>\n",
    "\n",
    "`Finally, run neaclass3.ipynb  and explain the differences with respect to neoclass2.ipynb. At the end of neaclass3.ipynb create a test dataset from  NEUdata_split/Test and  use it to evaluate the accuracy of both its models.`\n",
    "1. neaclass3 deepcopies the original pre-trained resnet18 model.\n",
    "2. neaclass3 uses a frozen vector layer\n",
    "<br>\n",
    "Accuracy for original Resnet18 model came out to 95%, whereas accuracy for the vector model came out to around 25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'RowanDLclassNEA' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from utils import DatasetUtils\n",
    "import torch\n",
    "from torch import optim \n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import DatasetFolder\n",
    "import cv2\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "!git clone https://github.com/skokalj/RowanDLclassNEA.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "### Design a convolutional autoencoder for a dataset of images 3 x 224 x224. Train it on NEU data for 50 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll start with getting the testing & training data and transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(img_path:str):    \n",
    "        np_img = cv2.imread(img_path)\n",
    "        return Image.fromarray(np_img)\n",
    "\"\"\"\n",
    "\n",
    "test_loader = DatasetUtils.create_loader_and_transform(\n",
    "    root_path='RowanDLclassNEA/NEUdata_split/Test', \n",
    "    loader_func=load_image, \n",
    "    extensions=('.bmp',), \n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    is_test=True\n",
    ")\n",
    "\n",
    "train_loader, val_loader, train_set, val_set = DatasetUtils.create_loader_and_transform(\n",
    "    root_path='RowanDLclassNEA/NEUdata', \n",
    "    loader_func=load_image, \n",
    "    extensions=('.bmp',), \n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    is_test=False\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "dset = DatasetFolder(root='RowanDLclassNEA/NEUdata', loader = load_image, extensions = ('.bmp',))\n",
    "\n",
    "transform = transforms.Compose([\n",
    "  transforms.Resize(256),\n",
    "  transforms.CenterCrop(224),\n",
    "  transforms.ToTensor(),\n",
    "  transforms.Normalize(\n",
    "      mean=[0.485, 0.456, 0.406],\n",
    "      std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "\n",
    "test_xform = transforms.Compose([\n",
    "  transforms.ToTensor(),\n",
    "  transforms.Normalize(\n",
    "      mean=[0.485, 0.456, 0.406],\n",
    "      std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "dset = DatasetFolder(root='RowanDLclassNEA/NEUdata', loader = load_image, extensions = ('.bmp',), transform = transform)\n",
    "test_data = DatasetFolder(root='RowanDLclassNEA/NEUdata_split/Test', loader = load_image, extensions=('.bmp'), transform=test_xform)\n",
    "\n",
    "\n",
    "train_set, val_set = random_split(\n",
    "                      dset, \n",
    "                      [1200, 600])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "                    train_set, \n",
    "                    batch_size=16, \n",
    "                    shuffle=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "                    val_set, \n",
    "                    batch_size=16, \n",
    "                    shuffle=True)\n",
    "\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "            test_data,\n",
    "            batch_size = 16,\n",
    "            shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Found that pooling layers were needed for this just to bring the memory usage down to a reasonable level. I experimented with unpooling in the decoder but couldn't get it to work properly with the training loop. <br><br> Also ran into dimensionality issues when adding more layers, even after applying (seemingly) similar upsampling functions in the decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "            Encoder:\n",
    "                Standard 3x3 kernels on the convolutional layers for feature extraction\n",
    "                2x2 kernels on the pooling layers for halving the input and reducing dimensions\n",
    "        \"\"\"\n",
    "        self.encoder = nn.Sequential(\n",
    "            \n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),  \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            \n",
    "            # bad things happen beyond this point\n",
    "            #nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "            #nn.ReLU(inplace=True),\n",
    "            #nn.MaxPool2d(2, stride=2),\n",
    "        )\n",
    "        \n",
    "        \"\"\"\n",
    "            Decoder:\n",
    "                Convolutional Transpose with kernel size 2 will double the size of the input\n",
    "        \"\"\"\n",
    "        self.decoder = nn.Sequential(\n",
    "           \n",
    "            #nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2),\n",
    "            #nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.ConvTranspose2d(64, 3, kernel_size=2, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(\"Input shape:\", x.shape)\n",
    "        x = self.encoder(x)\n",
    "        #print(\"Shape after encoding:\", x.shape)\n",
    "        x = self.decoder(x)\n",
    "        #print(\"Shape after decoding:\", x.shape)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learning rate scheduler made a noticeable difference in bringing the training and value losses closer together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Loss: 0.8836342791716257 Val Loss: 0.8577189288641277\n",
      "Epoch: 1 Train Loss: 0.8691731949647268 Val Loss: 0.8450094939846742\n",
      "Epoch: 2 Train Loss: 0.8580421137809754 Val Loss: 0.8356853001996091\n",
      "Epoch: 3 Train Loss: 0.7862159093221028 Val Loss: 0.643352315614098\n",
      "Epoch: 4 Train Loss: 0.4490959340333939 Val Loss: 0.3506934850623733\n",
      "Epoch: 5 Train Loss: 0.33270192325115205 Val Loss: 0.32070619769786535\n",
      "Epoch: 6 Train Loss: 0.31519589324792224 Val Loss: 0.3194767879812341\n",
      "Epoch: 7 Train Loss: 0.3126529341936111 Val Loss: 0.3178931815843833\n",
      "Epoch: 8 Train Loss: 0.3115619043509165 Val Loss: 0.3139228628654229\n",
      "Epoch: 9 Train Loss: 0.3091047300895055 Val Loss: 0.31438677875619186\n",
      "Epoch: 10 Train Loss: 0.30669766147931415 Val Loss: 0.312929652239147\n",
      "Epoch: 11 Train Loss: 0.3029148026307424 Val Loss: 0.3066292361993539\n",
      "Epoch: 12 Train Loss: 0.30223767876625063 Val Loss: 0.30576399321618836\n",
      "Epoch: 13 Train Loss: 0.3018871514002482 Val Loss: 0.31123615566052887\n",
      "Epoch: 14 Train Loss: 0.3016175454854965 Val Loss: 0.30443452494709117\n",
      "Epoch: 15 Train Loss: 0.30133081555366514 Val Loss: 0.3065966938279177\n",
      "Epoch: 16 Train Loss: 0.30125762601693473 Val Loss: 0.3039203188137004\n",
      "Epoch: 17 Train Loss: 0.3009108660618464 Val Loss: 0.3076879397818917\n",
      "Epoch: 18 Train Loss: 0.3006820718447367 Val Loss: 0.30519935645555196\n",
      "Epoch: 19 Train Loss: 0.30066129902998606 Val Loss: 0.30581678881456975\n",
      "Epoch: 20 Train Loss: 0.3002691427866618 Val Loss: 0.3039649815151566\n",
      "Epoch: 21 Train Loss: 0.30007310380538305 Val Loss: 0.30444974295402827\n",
      "Epoch: 22 Train Loss: 0.2998913641770681 Val Loss: 0.3039085268974304\n",
      "Epoch: 23 Train Loss: 0.2996474569042524 Val Loss: 0.30517105562122243\n",
      "Epoch: 24 Train Loss: 0.2993999739487966 Val Loss: 0.3041058127817355\n",
      "Epoch: 25 Train Loss: 0.2991870814561844 Val Loss: 0.30471136813101013\n",
      "Epoch: 26 Train Loss: 0.29899554590384164 Val Loss: 0.3022692583893475\n",
      "Epoch: 27 Train Loss: 0.2987312849362691 Val Loss: 0.3037035233880344\n",
      "Epoch: 28 Train Loss: 0.2985475854078929 Val Loss: 0.3027778993311681\n",
      "Epoch: 29 Train Loss: 0.2983104779322942 Val Loss: 0.3052740928373839\n",
      "Epoch: 30 Train Loss: 0.29808204690615336 Val Loss: 0.3049094947545152\n",
      "Epoch: 31 Train Loss: 0.2978539717197418 Val Loss: 0.30460126031386225\n",
      "Epoch: 32 Train Loss: 0.29766661127408345 Val Loss: 0.3017938584089279\n",
      "Epoch: 33 Train Loss: 0.2973275470733643 Val Loss: 0.3013603914725153\n",
      "Epoch: 34 Train Loss: 0.29713149587313337 Val Loss: 0.30076785228754344\n",
      "Epoch: 35 Train Loss: 0.29683283110459646 Val Loss: 0.3025690850458647\n",
      "Epoch: 36 Train Loss: 0.29660847067832946 Val Loss: 0.2999793212664755\n",
      "Epoch: 37 Train Loss: 0.29635731875896454 Val Loss: 0.3006308663048242\n",
      "Epoch: 38 Train Loss: 0.29610854109128315 Val Loss: 0.30086015792269455\n",
      "Epoch: 39 Train Loss: 0.2958852654695511 Val Loss: 0.2997331972184934\n",
      "Epoch: 40 Train Loss: 0.2956007512410482 Val Loss: 0.301430219882413\n",
      "Epoch: 41 Train Loss: 0.29546076953411105 Val Loss: 0.30040645422904116\n",
      "Epoch: 42 Train Loss: 0.2950936889648437 Val Loss: 0.3002532220592624\n",
      "Epoch: 43 Train Loss: 0.2948906377951304 Val Loss: 0.299881891200417\n",
      "Epoch: 44 Train Loss: 0.29471404512723287 Val Loss: 0.29819967558509425\n",
      "Epoch: 45 Train Loss: 0.29439331928888957 Val Loss: 0.30422698431893397\n",
      "Epoch: 46 Train Loss: 0.294106409351031 Val Loss: 0.30315982707236944\n",
      "Epoch: 47 Train Loss: 0.2938011805216471 Val Loss: 0.2986074756634863\n",
      "Epoch: 48 Train Loss: 0.29354248722394305 Val Loss: 0.3006874413082474\n",
      "Epoch: 49 Train Loss: 0.29327094157536826 Val Loss: 0.30129923710697576\n"
     ]
    }
   ],
   "source": [
    "ae_model = Autoencoder()\n",
    "device = device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "ae_model = ae_model.to(device)\n",
    "\n",
    "criterion = nn.MSELoss()    \n",
    "optimizer = optim.SGD(ae_model.parameters(), \n",
    "                      lr=0.010, \n",
    "                      momentum=0.9)\n",
    "\n",
    "scheduler = lr_scheduler.LinearLR(optimizer, start_factor=1.0, end_factor=0.25, total_iters=10)\n",
    "N_EPOCHS = 50\n",
    "tr_loss_hist = []\n",
    "val_loss_hist = []\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    # Training \n",
    "    train_loss = 0.0\n",
    "    ae_model.train()\n",
    "    for batch in train_loader:\n",
    "        images,_ = batch\n",
    "        images = images.cuda()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = ae_model(images)\n",
    "        loss = criterion(outputs, images)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    val_loss = 0.0\n",
    "    ae_model.eval()\n",
    "    for batch in val_loader:\n",
    "        images,_ = batch\n",
    "        images = images.cuda()\n",
    "\n",
    "        outputs = ae_model(images)\n",
    "        loss = criterion(outputs, images)\n",
    "\n",
    "        val_loss += loss.item()\n",
    "\n",
    "    print(\"Epoch: {} Train Loss: {} Val Loss: {}\".format(\n",
    "                  epoch, \n",
    "                  train_loss/len(train_loader), \n",
    "                  val_loss/len(val_loader)))\n",
    "    tr_loss_hist.append(train_loss/len(train_loader))\n",
    "    val_loss_hist.append(val_loss/len(val_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "<p> Instead of testing the autoencoder on classification, we'll test the data loss between encoding and decoding. </p> <br>\n",
    "<p>Mean Squared Error will capture any large outliers by squaring the errors before averaging them, thus magnifying any mistakes made. L1, or Mean Absolute Error will weigh all mistakes equally by giving a linear penalty to each error </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MSE Loss: 0.23148766967157522\n",
      "Average L1 Loss: 0.3346910576025645\n"
     ]
    }
   ],
   "source": [
    "total_mse_loss = 0.0\n",
    "total_L1_loss = 0.0\n",
    "\n",
    "ae_model.eval()\n",
    "\n",
    "for x_test_batch, _ in test_loader:  \n",
    "\n",
    "    x_test_batch = x_test_batch.to(device)\n",
    "\n",
    "    reconstructed_batch = ae_model(x_test_batch)\n",
    "    \n",
    "    mse_loss = nn.MSELoss()(reconstructed_batch, x_test_batch)\n",
    "    L1_loss = nn.L1Loss()(reconstructed_batch, x_test_batch)\n",
    "\n",
    "    total_mse_loss += mse_loss.item()\n",
    "    total_L1_loss += L1_loss.item()\n",
    "\n",
    "average_mse_loss = total_mse_loss / len(test_loader)\n",
    "average_L1_loss = total_L1_loss / len(test_loader)\n",
    "\n",
    "print(f'Average MSE Loss: {average_mse_loss}')\n",
    "print(f'Average L1 Loss: {average_L1_loss}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
